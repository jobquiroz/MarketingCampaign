{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intense-caution",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "executed-property",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# From sklearn\n",
    "\n",
    "# Custom cleaning functions\n",
    "from utils import cleaning_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-publisher",
   "metadata": {},
   "source": [
    "## Part 2: Supervised Learning Model\n",
    "\n",
    "Now that you've found which parts of the population are more likely to be customers of the mail-order company, it's time to build a prediction model. Each of the rows in the \"MAILOUT\" data files represents an individual that was targeted for a mailout campaign. Ideally, we should be able to use the demographic information from each individual to decide whether or not it will be worth it to include that person in the campaign.\n",
    "\n",
    "The \"MAILOUT\" data has been split into two approximately equal parts, each with almost 43 000 data rows. In this part, you can verify your model with the \"TRAIN\" partition, which includes a column, \"RESPONSE\", that states whether or not a person became a customer of the company following the campaign. In the next part, you'll need to create predictions on the \"TEST\" partition, where the \"RESPONSE\" column has been withheld."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-settlement",
   "metadata": {},
   "source": [
    "#### Reading and cleaning training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "familiar-darkness",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jobqu\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3155: DtypeWarning: Columns (19,20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "mailout_train = pd.read_csv('data/Udacity_MAILOUT_052018_TRAIN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "objective-trustee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial amount of missing values: 2217201\n",
      "\n",
      "Reading the description of attributes table....\n",
      "\n",
      "Missing values after including missing codes 2354411\n",
      "Additional missing values: 137210\n",
      "\n",
      "Starting the cleaning of attributes and feature engineering...\n"
     ]
    }
   ],
   "source": [
    "training_clean = cleaning_functions.clean_data(mailout_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "following-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_clean.drop(['LNR'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "standard-hierarchy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARBEIT</th>\n",
       "      <th>BALLRAUM</th>\n",
       "      <th>CJT_KATALOGNUTZER</th>\n",
       "      <th>CJT_TYP_1</th>\n",
       "      <th>CJT_TYP_2</th>\n",
       "      <th>CJT_TYP_3</th>\n",
       "      <th>CJT_TYP_4</th>\n",
       "      <th>CJT_TYP_5</th>\n",
       "      <th>CJT_TYP_6</th>\n",
       "      <th>D19_BANKEN_ANZ_12</th>\n",
       "      <th>...</th>\n",
       "      <th>REGIOTYP_7.0</th>\n",
       "      <th>CAMEO_DEUG_2015_1.0</th>\n",
       "      <th>CAMEO_DEUG_2015_2.0</th>\n",
       "      <th>CAMEO_DEUG_2015_3.0</th>\n",
       "      <th>CAMEO_DEUG_2015_4.0</th>\n",
       "      <th>CAMEO_DEUG_2015_5.0</th>\n",
       "      <th>CAMEO_DEUG_2015_6.0</th>\n",
       "      <th>CAMEO_DEUG_2015_7.0</th>\n",
       "      <th>CAMEO_DEUG_2015_8.0</th>\n",
       "      <th>CAMEO_DEUG_2015_9.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ARBEIT  BALLRAUM  CJT_KATALOGNUTZER  CJT_TYP_1  CJT_TYP_2  CJT_TYP_3  \\\n",
       "0     3.0       5.0                5.0        2.0        2.0        5.0   \n",
       "1     2.0       5.0                2.0        2.0        2.0        4.0   \n",
       "2     4.0       1.0                5.0        1.0        1.0        5.0   \n",
       "3     4.0       2.0                5.0        2.0        2.0        5.0   \n",
       "4     3.0       4.0                5.0        1.0        2.0        5.0   \n",
       "\n",
       "   CJT_TYP_4  CJT_TYP_5  CJT_TYP_6  D19_BANKEN_ANZ_12  ...  REGIOTYP_7.0  \\\n",
       "0        5.0        5.0        5.0                  0  ...             0   \n",
       "1        3.0        5.0        4.0                  1  ...             0   \n",
       "2        5.0        5.0        5.0                  0  ...             0   \n",
       "3        5.0        5.0        4.0                  0  ...             0   \n",
       "4        5.0        5.0        5.0                  0  ...             1   \n",
       "\n",
       "   CAMEO_DEUG_2015_1.0  CAMEO_DEUG_2015_2.0  CAMEO_DEUG_2015_3.0  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    1                    0   \n",
       "3                    0                    1                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   CAMEO_DEUG_2015_4.0  CAMEO_DEUG_2015_5.0  CAMEO_DEUG_2015_6.0  \\\n",
       "0                    0                    1                    0   \n",
       "1                    0                    1                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   CAMEO_DEUG_2015_7.0  CAMEO_DEUG_2015_8.0  CAMEO_DEUG_2015_9.0  \n",
       "0                    0                    0                    0  \n",
       "1                    0                    0                    0  \n",
       "2                    0                    0                    0  \n",
       "3                    0                    0                    0  \n",
       "4                    1                    0                    0  \n",
       "\n",
       "[5 rows x 213 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-preservation",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cooked-modeling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARBEIT</th>\n",
       "      <th>BALLRAUM</th>\n",
       "      <th>CJT_KATALOGNUTZER</th>\n",
       "      <th>CJT_TYP_1</th>\n",
       "      <th>CJT_TYP_2</th>\n",
       "      <th>CJT_TYP_3</th>\n",
       "      <th>CJT_TYP_4</th>\n",
       "      <th>CJT_TYP_5</th>\n",
       "      <th>CJT_TYP_6</th>\n",
       "      <th>D19_BANKEN_ANZ_12</th>\n",
       "      <th>...</th>\n",
       "      <th>REGIOTYP_6.0</th>\n",
       "      <th>REGIOTYP_7.0</th>\n",
       "      <th>CAMEO_DEUG_2015_1.0</th>\n",
       "      <th>CAMEO_DEUG_2015_2.0</th>\n",
       "      <th>CAMEO_DEUG_2015_3.0</th>\n",
       "      <th>CAMEO_DEUG_2015_4.0</th>\n",
       "      <th>CAMEO_DEUG_2015_5.0</th>\n",
       "      <th>CAMEO_DEUG_2015_6.0</th>\n",
       "      <th>CAMEO_DEUG_2015_7.0</th>\n",
       "      <th>CAMEO_DEUG_2015_8.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.220282</td>\n",
       "      <td>0.203551</td>\n",
       "      <td>0.756779</td>\n",
       "      <td>-0.396140</td>\n",
       "      <td>-0.211671</td>\n",
       "      <td>0.563449</td>\n",
       "      <td>0.580345</td>\n",
       "      <td>0.560862</td>\n",
       "      <td>0.580973</td>\n",
       "      <td>-0.224018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286551</td>\n",
       "      <td>-0.242063</td>\n",
       "      <td>-0.350607</td>\n",
       "      <td>-0.338773</td>\n",
       "      <td>-0.368279</td>\n",
       "      <td>3.996789</td>\n",
       "      <td>-0.66823</td>\n",
       "      <td>-0.277121</td>\n",
       "      <td>-0.36333</td>\n",
       "      <td>-0.24645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.216569</td>\n",
       "      <td>0.203551</td>\n",
       "      <td>-1.329511</td>\n",
       "      <td>-0.396140</td>\n",
       "      <td>-0.211671</td>\n",
       "      <td>-0.521138</td>\n",
       "      <td>-1.309792</td>\n",
       "      <td>0.560862</td>\n",
       "      <td>-0.443101</td>\n",
       "      <td>1.978334</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286551</td>\n",
       "      <td>-0.242063</td>\n",
       "      <td>-0.350607</td>\n",
       "      <td>-0.338773</td>\n",
       "      <td>-0.368279</td>\n",
       "      <td>3.996789</td>\n",
       "      <td>-0.66823</td>\n",
       "      <td>-0.277121</td>\n",
       "      <td>-0.36333</td>\n",
       "      <td>-0.24645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.776006</td>\n",
       "      <td>-1.704266</td>\n",
       "      <td>0.756779</td>\n",
       "      <td>-1.138807</td>\n",
       "      <td>-0.929186</td>\n",
       "      <td>0.563449</td>\n",
       "      <td>0.580345</td>\n",
       "      <td>0.560862</td>\n",
       "      <td>0.580973</td>\n",
       "      <td>-0.224018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286551</td>\n",
       "      <td>-0.242063</td>\n",
       "      <td>2.852196</td>\n",
       "      <td>-0.338773</td>\n",
       "      <td>-0.368279</td>\n",
       "      <td>-0.250201</td>\n",
       "      <td>-0.66823</td>\n",
       "      <td>-0.277121</td>\n",
       "      <td>-0.36333</td>\n",
       "      <td>-0.24645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.776006</td>\n",
       "      <td>-1.227312</td>\n",
       "      <td>0.756779</td>\n",
       "      <td>-0.396140</td>\n",
       "      <td>-0.211671</td>\n",
       "      <td>0.563449</td>\n",
       "      <td>0.580345</td>\n",
       "      <td>0.560862</td>\n",
       "      <td>-0.443101</td>\n",
       "      <td>-0.224018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286551</td>\n",
       "      <td>-0.242063</td>\n",
       "      <td>2.852196</td>\n",
       "      <td>-0.338773</td>\n",
       "      <td>-0.368279</td>\n",
       "      <td>-0.250201</td>\n",
       "      <td>-0.66823</td>\n",
       "      <td>-0.277121</td>\n",
       "      <td>-0.36333</td>\n",
       "      <td>-0.24645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.220282</td>\n",
       "      <td>-0.273403</td>\n",
       "      <td>0.756779</td>\n",
       "      <td>-1.138807</td>\n",
       "      <td>-0.211671</td>\n",
       "      <td>0.563449</td>\n",
       "      <td>0.580345</td>\n",
       "      <td>0.560862</td>\n",
       "      <td>0.580973</td>\n",
       "      <td>-0.224018</td>\n",
       "      <td>...</td>\n",
       "      <td>3.489775</td>\n",
       "      <td>-0.242063</td>\n",
       "      <td>-0.350607</td>\n",
       "      <td>-0.338773</td>\n",
       "      <td>-0.368279</td>\n",
       "      <td>-0.250201</td>\n",
       "      <td>-0.66823</td>\n",
       "      <td>3.608537</td>\n",
       "      <td>-0.36333</td>\n",
       "      <td>-0.24645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ARBEIT  BALLRAUM  CJT_KATALOGNUTZER  CJT_TYP_1  CJT_TYP_2  CJT_TYP_3  \\\n",
       "0 -0.220282  0.203551           0.756779  -0.396140  -0.211671   0.563449   \n",
       "1 -1.216569  0.203551          -1.329511  -0.396140  -0.211671  -0.521138   \n",
       "2  0.776006 -1.704266           0.756779  -1.138807  -0.929186   0.563449   \n",
       "3  0.776006 -1.227312           0.756779  -0.396140  -0.211671   0.563449   \n",
       "4 -0.220282 -0.273403           0.756779  -1.138807  -0.211671   0.563449   \n",
       "\n",
       "   CJT_TYP_4  CJT_TYP_5  CJT_TYP_6  D19_BANKEN_ANZ_12  ...  REGIOTYP_6.0  \\\n",
       "0   0.580345   0.560862   0.580973          -0.224018  ...     -0.286551   \n",
       "1  -1.309792   0.560862  -0.443101           1.978334  ...     -0.286551   \n",
       "2   0.580345   0.560862   0.580973          -0.224018  ...     -0.286551   \n",
       "3   0.580345   0.560862  -0.443101          -0.224018  ...     -0.286551   \n",
       "4   0.580345   0.560862   0.580973          -0.224018  ...      3.489775   \n",
       "\n",
       "   REGIOTYP_7.0  CAMEO_DEUG_2015_1.0  CAMEO_DEUG_2015_2.0  \\\n",
       "0     -0.242063            -0.350607            -0.338773   \n",
       "1     -0.242063            -0.350607            -0.338773   \n",
       "2     -0.242063             2.852196            -0.338773   \n",
       "3     -0.242063             2.852196            -0.338773   \n",
       "4     -0.242063            -0.350607            -0.338773   \n",
       "\n",
       "   CAMEO_DEUG_2015_3.0  CAMEO_DEUG_2015_4.0  CAMEO_DEUG_2015_5.0  \\\n",
       "0            -0.368279             3.996789             -0.66823   \n",
       "1            -0.368279             3.996789             -0.66823   \n",
       "2            -0.368279            -0.250201             -0.66823   \n",
       "3            -0.368279            -0.250201             -0.66823   \n",
       "4            -0.368279            -0.250201             -0.66823   \n",
       "\n",
       "   CAMEO_DEUG_2015_6.0  CAMEO_DEUG_2015_7.0  CAMEO_DEUG_2015_8.0  \n",
       "0            -0.277121             -0.36333             -0.24645  \n",
       "1            -0.277121             -0.36333             -0.24645  \n",
       "2            -0.277121             -0.36333             -0.24645  \n",
       "3            -0.277121             -0.36333             -0.24645  \n",
       "4             3.608537             -0.36333             -0.24645  \n",
       "\n",
       "[5 rows x 212 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_scaled = scaler.fit_transform(training_clean.drop(['RESPONSE'], axis = 1))\n",
    "\n",
    "train_scaled = pd.DataFrame(train_scaled, columns = list(training_clean.columns)[:-1])\n",
    "\n",
    "train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-attack",
   "metadata": {},
   "source": [
    "### Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "precise-recipe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "X = train_scaled.values\n",
    "y = training_clean['RESPONSE'].values\n",
    "\n",
    "clf = SGDClassifier()\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "opening-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "catholic-interest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42418    12]\n",
      " [  532     0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49985859061984445"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "\n",
    "print( confusion_matrix(y, preds) )\n",
    "\n",
    "roc_auc_score(y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-intermediate",
   "metadata": {},
   "source": [
    "### RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "automotive-syndication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "rf_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "varying-roots",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42430     0]\n",
      " [   57   475]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9464285714285714"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = rf_clf.predict(X)\n",
    "\n",
    "print( confusion_matrix(y, preds) )\n",
    "\n",
    "roc_auc_score(y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-expert",
   "metadata": {},
   "source": [
    "#### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "hairy-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "y_pred = cross_val_predict(rf_clf, X, y)  # cv = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "downtown-crime",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42418    12]\n",
      " [  532     0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49985859061984445"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( confusion_matrix(y, y_pred) )\n",
    "\n",
    "roc_auc_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-islam",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "talented-thompson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42430     0]\n",
      " [  532     0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators = 500, max_leaf_nodes = 16, n_jobs = -1, random_state = 42)\n",
    "\n",
    "y_pred = cross_val_predict(rf_clf, X, y)  # cv = 5\n",
    "\n",
    "print( confusion_matrix(y, y_pred) )\n",
    "\n",
    "roc_auc_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-static",
   "metadata": {},
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "toxic-austin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34369 8593 34369 8593\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)\n",
    "\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-large",
   "metadata": {},
   "source": [
    "### Hyperparameter grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "amino-blast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 300 candidates, totalling 900 fits\n",
      "{'max_depth': 5, 'max_features': 0.33, 'min_samples_leaf': 15, 'n_estimators': 200}\n",
      "0.7667679199174828\n",
      "0.8570148710215321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rfc = RandomForestClassifier() # class_weight = 'balanced')\n",
    "\n",
    "rf_hyperparameters = {'n_estimators': [150, 175, 185, 200], #, 250, 300],  \n",
    "                      'max_depth': [ 3, 4, 5, 6, 7], \n",
    "                      'max_features': ['auto', 'sqrt', 0.33],\n",
    "                      'min_samples_leaf': [3, 5, 10, 12, 15]}\n",
    "\n",
    "model = GridSearchCV(rfc, rf_hyperparameters, scoring = 'roc_auc', n_jobs = -1, verbose = 10, cv = 3)\n",
    "\n",
    "preds = model.fit(X, y)\n",
    "\n",
    "print(model.best_params_)\n",
    "\n",
    "print(model.best_score_)\n",
    "\n",
    "rfc_final = model.best_estimator_\n",
    "\n",
    "y_pred= rfc_final.predict_proba(X)[:,1]\n",
    "\n",
    "print(roc_auc_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_bal = RandomForestClassifier(class_weight = 'balanced')\n",
    "\n",
    "rf_hyperparameters = {'n_estimators': [125, 150, 175], #, 250, 300],  \n",
    "                      'max_depth': [2, 3, 4, 5, 6, 10], \n",
    "                      'max_features': ['auto', 'sqrt', 0.33],\n",
    "                      'min_samples_leaf': [3, 10, 15]}\n",
    "\n",
    "model_bal = GridSearchCV(rfc_bal, rf_hyperparameters, scoring = 'roc_auc', n_jobs = -1, verbose = 10, cv = 3)\n",
    "\n",
    "preds = model_bal.fit(X_train, y_train)\n",
    "\n",
    "print(model_bal.best_params_)\n",
    "\n",
    "print(model_bal.best_score_)\n",
    "\n",
    "rfc_bal_final = model_bal.best_estimator_\n",
    "\n",
    "y_pred_train = rfc_bal_final.predict_proba(X_train)[:,1]\n",
    "y_pred_test = rfc_bal_final.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(roc_auc_score(y_train, y_pred_train))\n",
    "\n",
    "print(roc_auc_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-thumb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "found-reservoir",
   "metadata": {},
   "source": [
    "## Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "appropriate-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "checked-dakota",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t212\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t212\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t212\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t212\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t212\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t212\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t212\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t11\n",
      "Rejected: \t201\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t7\n",
      "Tentative: \t4\n",
      "Rejected: \t201\n",
      "Iteration: \t10 / 100\n",
      "Confirmed: \t7\n",
      "Tentative: \t4\n",
      "Rejected: \t201\n",
      "Iteration: \t11 / 100\n",
      "Confirmed: \t7\n",
      "Tentative: \t4\n",
      "Rejected: \t201\n",
      "Iteration: \t12 / 100\n",
      "Confirmed: \t7\n",
      "Tentative: \t2\n",
      "Rejected: \t203\n",
      "Iteration: \t13 / 100\n",
      "Confirmed: \t7\n",
      "Tentative: \t2\n",
      "Rejected: \t203\n",
      "Iteration: \t14 / 100\n",
      "Confirmed: \t7\n",
      "Tentative: \t2\n",
      "Rejected: \t203\n",
      "Iteration: \t15 / 100\n",
      "Confirmed: \t7\n",
      "Tentative: \t2\n",
      "Rejected: \t203\n",
      "Iteration: \t16 / 100\n",
      "Confirmed: \t7\n",
      "Tentative: \t2\n",
      "Rejected: \t203\n",
      "Iteration: \t17 / 100\n",
      "Confirmed: \t7\n",
      "Tentative: \t2\n",
      "Rejected: \t203\n",
      "Iteration: \t18 / 100\n",
      "Confirmed: \t7\n",
      "Tentative: \t2\n",
      "Rejected: \t203\n",
      "Iteration: \t19 / 100\n",
      "Confirmed: \t7\n",
      "Tentative: \t2\n",
      "Rejected: \t203\n",
      "Iteration: \t20 / 100\n",
      "Confirmed: \t7\n",
      "Tentative: \t2\n",
      "Rejected: \t203\n",
      "Iteration: \t21 / 100\n",
      "Confirmed: \t7\n",
      "Tentative: \t2\n",
      "Rejected: \t203\n",
      "Iteration: \t22 / 100\n",
      "Confirmed: \t7\n",
      "Tentative: \t0\n",
      "Rejected: \t205\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t23 / 100\n",
      "Confirmed: \t7\n",
      "Tentative: \t0\n",
      "Rejected: \t205\n"
     ]
    }
   ],
   "source": [
    "from boruta import BorutaPy\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=-1, max_depth = 5, class_weight = 'balanced')\n",
    "\n",
    "trans = BorutaPy(clf, n_estimators = 'auto', random_state = 42, verbose=2, max_iter = 100)\n",
    "\n",
    "X_filtered = trans.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "perceived-designation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "\n",
    "clf.fit(X_filtered, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "sixth-jesus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42430     0]\n",
      " [  532     0]]\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_filtered)\n",
    "\n",
    "print( confusion_matrix(y, preds) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "incident-smell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.81144176, -0.40948314,  1.48920468, ...,  0.24875853,\n",
       "         1.65974792, -0.69625873],\n",
       "       [-0.19024662,  2.45616514, -1.52973644, ...,  0.06318366,\n",
       "        -0.60250113, -0.69625873],\n",
       "       [-0.81144176,  0.30692893, -1.52973644, ...,  1.36220777,\n",
       "        -0.60250113, -0.69625873],\n",
       "       ...,\n",
       "       [-0.81144176, -0.40948314,  0.28162823, ...,  0.666302  ,\n",
       "        -0.60250113, -0.69625873],\n",
       "       [-1.12203933, -1.12589521,  0.88541646, ...,  0.01678994,\n",
       "        -0.60250113, -0.69625873],\n",
       "       [ 1.05214367, -1.12589521,  0.88541646, ...,  1.03745174,\n",
       "        -0.60250113,  1.4362477 ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-retailer",
   "metadata": {},
   "source": [
    "### Using X_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "continent-invalid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n",
      "{'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 10, 'n_estimators': 200}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7722916515062119"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cl = RandomForestClassifier(class_weight = 'balanced')\n",
    "\n",
    "rf_hyperparameters = {'n_estimators': [150, 200, 250, 300],  \n",
    "                      'max_depth': [2, 3, 4, 6, 10], \n",
    "                      'max_features': ['auto', 'sqrt', 0.33],\n",
    "                      'min_samples_leaf': [3, 10, 15]}\n",
    "\n",
    "model_bor = GridSearchCV(rf_cl, rf_hyperparameters, scoring = 'roc_auc', n_jobs = -1, verbose = 10, cv = 5)\n",
    "\n",
    "preds = model_bor.fit(X_filtered, y)\n",
    "\n",
    "print(model_bor.best_params_)\n",
    "model_bor.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-stomach",
   "metadata": {},
   "source": [
    "#### Spliting X_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "running-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf_train, Xf_test, yf_train, yf_test = train_test_split(X_filtered, y, test_size = 0.2, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "worthy-incentive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n",
      "{'max_depth': 6, 'max_features': 0.33, 'min_samples_leaf': 10, 'n_estimators': 150}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7722197024403383"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cl_2 = RandomForestClassifier()\n",
    "\n",
    "rf_hyperparameters = {'n_estimators': [150, 200, 250, 300],  \n",
    "                      'max_depth': [2, 3, 4, 6, 10], \n",
    "                      'max_features': ['auto', 'sqrt', 0.33],\n",
    "                      'min_samples_leaf': [3, 10, 15]}\n",
    "\n",
    "model_bor2 = GridSearchCV(rf_cl_2, rf_hyperparameters, scoring = 'roc_auc', n_jobs = -1, verbose = 10, cv = 5)\n",
    "\n",
    "preds = model_bor2.fit(Xf_train, yf_train)\n",
    "\n",
    "print(model_bor2.best_params_)\n",
    "model_bor2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "musical-tracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.828012206047172\n",
      "0.7796613466544838\n"
     ]
    }
   ],
   "source": [
    "boruta_rf2_best = model_bor2.best_estimator_\n",
    "\n",
    "y_bor_pred_train = boruta_rf2_best.predict_proba(Xf_train)[:,1]\n",
    "y_bor_pred_test = boruta_rf2_best.predict_proba(Xf_test)[:,1]\n",
    "\n",
    "print(roc_auc_score(yf_train, y_bor_pred_train))\n",
    "\n",
    "print(roc_auc_score(yf_test, y_bor_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cordless-belize",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01104199, 0.03028916, 0.0070229 , ..., 0.01185699, 0.00395929,\n",
       "       0.00123843])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_bor_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "equal-notification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8487    0]\n",
      " [ 106    0]]\n"
     ]
    }
   ],
   "source": [
    "print( confusion_matrix(yf_test, boruta_rf2_best.predict(Xf_test)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-serbia",
   "metadata": {},
   "source": [
    "### XGBosst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "lightweight-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "brief-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dmatrix = xgb.DMatrix(data = X, label = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "violent-crossing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jobqu\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, eval_metric='auc',\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=5, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=10, n_jobs=-1,\n",
       "              num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                           colsample_bytree = 0.3, \n",
    "                           learning_rate = 0.1,\n",
    "                           max_depth = 5,\n",
    "                           n_estimators = 10,\n",
    "                           n_jobs = -1, \n",
    "                           eval_metric = 'auc')\n",
    "\n",
    "xgb_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "offshore-glass",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_xgb = xgb_clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fresh-aberdeen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42430     0]\n",
      " [  532     0]]\n"
     ]
    }
   ],
   "source": [
    "print( confusion_matrix(y, y_xgb) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-correspondence",
   "metadata": {},
   "source": [
    "### Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "compliant-deficit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jobqu\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.75, 'gamma': 0.001, 'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 100}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7600238185600064"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(n_jobs = -1, objective = 'binary:logistic', eval_metric = 'auc', scale_pos_weight = 99)\n",
    "\n",
    "xgb_hyperparameters = {'n_estimators': [10, 50, 100], \n",
    "                       'max_depth': [2, 5, 8],\n",
    "                       'gamma': [0.001, 0.01, 0.1],    \n",
    "                       'learning_rate': [0.001, 0.01, 0.1],\n",
    "                       'colsample_bytree': [0.75, 0.9, 1.0], \n",
    "                       # 'scale_pos_weight': [1, 80, 99, 100]\n",
    "                        }\n",
    "\n",
    "xgb_cv = GridSearchCV(xgb_clf, xgb_hyperparameters, scoring = 'roc_auc', n_jobs = -1, verbose = 3, cv = 3)\n",
    "\n",
    "xgb_cv.fit(X, y)\n",
    "\n",
    "print(xgb_cv.best_params_)\n",
    "xgb_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "polyphonic-florist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7781471339791856\n"
     ]
    }
   ],
   "source": [
    "xgb_final = xgb_cv.best_estimator_\n",
    "\n",
    "y_pred_prob = xgb_final.predict_proba(X)[:,1]\n",
    "\n",
    "print(roc_auc_score(y, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "sustained-kitty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24314 18116]\n",
      " [   73   459]]\n"
     ]
    }
   ],
   "source": [
    "print( confusion_matrix(y, xgb_final.predict(X)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "disturbed-wiring",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "whole-profit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_final.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-society",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-oxide",
   "metadata": {},
   "source": [
    "### Probar el anterior pero spliting X..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "invisible-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dominant-expert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jobqu\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.9, 'gamma': 0.001, 'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 50}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7595338253861099"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf_split = xgb.XGBClassifier(n_jobs = -1, objective = 'binary:logistic', eval_metric = 'auc', scale_pos_weight = 99)\n",
    "\n",
    "xgb_hyperparameters = {'n_estimators': [10, 50, 100], \n",
    "                       'max_depth': [2, 5, 8],\n",
    "                       'gamma': [0.001, 0.01, 0.1],    \n",
    "                       'learning_rate': [0.001, 0.01, 0.1],\n",
    "                       'colsample_bytree': [0.75, 0.9, 1.0], \n",
    "                       # 'scale_pos_weight': [1, 80, 99, 100]\n",
    "                        }\n",
    "\n",
    "xgb_cv_split = GridSearchCV(xgb_clf_split, xgb_hyperparameters, scoring = 'roc_auc', n_jobs = -1, verbose = 3, cv = 3)\n",
    "\n",
    "xgb_cv_split.fit(X_train, y_train)\n",
    "\n",
    "print(xgb_cv_split.best_params_)\n",
    "\n",
    "xgb_cv_split.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "greenhouse-touch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.778652391422848\n",
      "0.775495708197443\n"
     ]
    }
   ],
   "source": [
    "xgb_final_split = xgb_cv_split.best_estimator_\n",
    "\n",
    "y_train_prob = xgb_final_split.predict_proba(X_train)[:,1]\n",
    "y_test_prob = xgb_final_split.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(roc_auc_score(y_train, y_train_prob))\n",
    "print(roc_auc_score(y_test, y_test_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bronze-documentary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19477 14466]\n",
      " [   61   365]]\n"
     ]
    }
   ],
   "source": [
    "print( confusion_matrix(y_train, xgb_final_split.predict(X_train)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "plain-dylan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4837 3650]\n",
      " [  12   94]]\n"
     ]
    }
   ],
   "source": [
    "print( confusion_matrix(y_test, xgb_final_split.predict(X_test)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-adoption",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-performance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "continued-construction",
   "metadata": {},
   "source": [
    "### RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aging-blood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 400 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jobqu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.71663237 0.69226298 0.75398028 0.73496146 0.72372913 0.75018601\n",
      " 0.70373809 0.75542144 0.73061949 0.76043715 0.69474747 0.7374105\n",
      " 0.64102387 0.73142782 0.73806819 0.75828867 0.76022935        nan\n",
      " 0.74209905        nan 0.75441686 0.68018131 0.75831844 0.75263874\n",
      " 0.76147084 0.62820255        nan 0.75775887 0.73132865 0.6895007\n",
      " 0.68772957 0.73138537 0.74336084 0.75604273 0.7282428  0.75381216\n",
      " 0.74033653 0.74439593 0.7317754  0.58662157 0.76336647 0.71419946\n",
      " 0.72006834 0.56734973 0.73712328 0.73876155 0.68091828 0.73528423\n",
      "        nan 0.75699406 0.71249572 0.75880264 0.74633317 0.73978365\n",
      " 0.75986092 0.73928167 0.73456574        nan 0.75346608 0.7428183\n",
      "        nan 0.74622141 0.70232421 0.72997013 0.740285   0.72619752\n",
      " 0.71663827 0.73391804 0.69550644 0.73385057 0.66787364 0.7423218\n",
      " 0.69611814 0.75745267 0.75690806 0.69593565 0.61663025 0.71452575\n",
      " 0.66562019 0.74275325 0.65957225 0.74062761 0.72651745 0.71481589\n",
      " 0.76413516 0.74581333 0.72736651 0.75617448 0.62820969 0.71437771\n",
      " 0.68572604 0.74062469 0.71908694 0.75303585 0.65203146 0.64383256\n",
      " 0.7409689  0.58095632 0.72738323 0.63848513 0.73849838 0.75580443\n",
      " 0.73508065 0.7445769  0.69374612 0.73903006 0.75169332        nan\n",
      " 0.74435125        nan 0.74882139 0.68279128 0.55903999 0.73531487\n",
      " 0.70871207 0.73112911 0.75939519 0.73511976 0.76048644 0.70603847\n",
      " 0.75239173 0.75881487 0.7645985  0.7275934  0.73049873 0.75173054\n",
      " 0.71065033 0.76251739 0.71642426 0.64674119 0.70500243 0.74122475\n",
      " 0.74255011 0.7584208  0.68818624 0.75289669        nan 0.74052549\n",
      " 0.72779466 0.7437189  0.63979458 0.74543465 0.73626348 0.73693383\n",
      " 0.73768536 0.76264369 0.7128281  0.73950181 0.68326733 0.62613871\n",
      " 0.55568401 0.68410314        nan 0.71249572 0.7168905  0.7332931\n",
      " 0.6833956  0.7324448  0.75795783 0.75257174 0.65255274        nan\n",
      " 0.71718925 0.75741199 0.73150153 0.6937614  0.75318727        nan\n",
      " 0.7424735  0.73547581 0.76176554 0.68872625 0.72900196 0.75584932\n",
      " 0.66247836 0.7519552  0.75324129 0.73638797 0.64795757        nan\n",
      " 0.74169838 0.74583741 0.69987853 0.74659592 0.55674284 0.67143733\n",
      " 0.75454737 0.70177488 0.74932814 0.75284174 0.67508666 0.7374134\n",
      " 0.72843808 0.56862426 0.74490156 0.74389459 0.74347346 0.74107632\n",
      " 0.74548858        nan        nan 0.73769907        nan 0.73903062\n",
      " 0.74708    0.74127059 0.71208028 0.76224314 0.7290811  0.70385981\n",
      " 0.64983085 0.73207663 0.71774682 0.67272041 0.7351862  0.76263371\n",
      " 0.62379962 0.72539397 0.74565604 0.74866794 0.64153534 0.74626126\n",
      " 0.72354478 0.72653177 0.70973367 0.73317961 0.73524833 0.75711958\n",
      " 0.75301131 0.76572279 0.68304941 0.74399707 0.6672492  0.66698254\n",
      " 0.75421689        nan 0.74724719 0.66393247 0.71805229        nan\n",
      " 0.72248181 0.56340401 0.75079851 0.73896987        nan 0.76130535\n",
      " 0.73117313 0.75056189 0.76172201 0.75290373 0.67375112        nan\n",
      " 0.75053466 0.76302608        nan 0.74171487 0.74058038 0.69044205\n",
      " 0.73804144 0.73715461 0.73219401        nan 0.76626033 0.7654048\n",
      " 0.76517558 0.75984424 0.76177108 0.75268699 0.73817391 0.74429177\n",
      " 0.75185005 0.76365753 0.7393684         nan 0.73628357 0.73394404\n",
      " 0.7286053         nan        nan 0.72657741 0.65683465 0.75676051\n",
      " 0.6876869         nan 0.7604448  0.75863072 0.74904434 0.76584144\n",
      "        nan 0.76254327 0.70519919 0.7463659  0.70284707 0.71065489\n",
      " 0.71986156 0.75758838 0.72390071 0.71640176 0.73644738 0.69504954\n",
      " 0.74366366 0.76059805 0.74079079 0.72789033 0.74985477 0.6111289\n",
      "        nan 0.72720914 0.71145777 0.76045449 0.62609048 0.73148685\n",
      " 0.73561929 0.75839997 0.7534919  0.74142587 0.72509361 0.76552438\n",
      " 0.71961703 0.76148427 0.72648781 0.76513537 0.75557781 0.74052391\n",
      " 0.7425293  0.73968652        nan 0.74328532 0.73088265 0.73441155\n",
      " 0.70119403 0.74007296        nan 0.75055419        nan 0.71214281\n",
      " 0.60748024 0.74104572 0.71034424 0.72916811 0.75189072 0.73924667\n",
      " 0.74713551 0.74776721 0.75671639 0.76208907 0.72647736 0.75371473\n",
      " 0.73454637 0.76279905        nan 0.75489574 0.74399161 0.69548116\n",
      "        nan 0.71352607 0.69603512        nan 0.74184865 0.75183151\n",
      " 0.74851194 0.71560834 0.69271806        nan 0.71967728 0.68901141\n",
      " 0.73800317 0.73305908 0.7125934  0.74254283 0.75529851 0.76233391\n",
      " 0.76083753        nan 0.6956902  0.7601772  0.76218149 0.69649112\n",
      " 0.60616971 0.72470793 0.74544114 0.55590968 0.7534919  0.71271022\n",
      " 0.74355165 0.7290458  0.62991052 0.72863653 0.74782399 0.7307152\n",
      " 0.73631401 0.74515718 0.75079833 0.71730072 0.74671041 0.72711579\n",
      " 0.75174138 0.72989572 0.74035499 0.64601475]\n",
      "  warnings.warn(\n",
      "C:\\Users\\jobqu\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.5642169219293882, 'gamma': 0.0006324581847080217, 'learning_rate': 0.0034143277530612657, 'max_depth': 3, 'n_estimators': 50}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7662603267015683"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy.stats as stats\n",
    "from sklearn.utils.fixes import loguniform\n",
    "\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(n_jobs = -1, objective = 'binary:logistic', eval_metric = 'auc', \n",
    "                            scale_pos_weight = 99) #, use_label_encoder=False)\n",
    "\n",
    "xgb_distributions = {'n_estimators':[4, 5, 6, 7, 10, 50, 100, 150, 200],  # [5, 10, 50, 100], \n",
    "                       'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                       'gamma': loguniform(1e-4, 1e0),    \n",
    "                       'learning_rate': loguniform(1e-4, 1e0), \n",
    "                       'colsample_bytree':  stats.uniform(0.1, 1.0),}\n",
    "                       # 'scale_pos_weight': [1, 80, 99, 100]}\n",
    "\n",
    "xgb_r_cv = RandomizedSearchCV(xgb_clf, \n",
    "                        param_distributions = xgb_distributions, \n",
    "                        n_iter = 400,\n",
    "                        scoring = 'roc_auc', \n",
    "                        n_jobs = -1, \n",
    "                        verbose = 3, \n",
    "                        cv = 3)\n",
    "\n",
    "xgb_r_cv.fit(X, y)\n",
    "\n",
    "print(xgb_r_cv.best_params_)\n",
    "xgb_r_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-conditioning",
   "metadata": {},
   "source": [
    "Este ya se va a probar con test_set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "surprised-interview",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7983259911503955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[25080, 17350],\n",
       "       [   75,   457]], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_final = xgb_r_cv.best_estimator_\n",
    "\n",
    "y_pred_prob = xgb_final.predict_proba(X)[:,1]\n",
    "\n",
    "print(roc_auc_score(y, y_pred_prob))\n",
    "\n",
    "confusion_matrix(y, xgb_final.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-manchester",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-plenty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "developed-issue",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 300 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jobqu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.74306202        nan 0.7468537  0.71802416 0.76133924        nan\n",
      " 0.67856404        nan        nan 0.75509126        nan 0.75430993\n",
      "        nan        nan        nan        nan 0.75244012        nan\n",
      "        nan        nan 0.75672445        nan 0.76256494 0.74902801\n",
      " 0.76445047        nan 0.76214088 0.7571419         nan 0.757784\n",
      "        nan 0.76042916        nan        nan        nan        nan\n",
      "        nan 0.76565489        nan        nan        nan 0.74844483\n",
      " 0.76355961        nan 0.76588652        nan        nan        nan\n",
      " 0.75910042 0.76101485 0.75739955 0.72461913        nan        nan\n",
      " 0.76265693 0.75588819        nan        nan 0.75691697        nan\n",
      " 0.75580315        nan        nan 0.75733609 0.7669301         nan\n",
      "        nan        nan        nan 0.76149666        nan        nan\n",
      " 0.75624403        nan 0.75615663        nan 0.76143679        nan\n",
      " 0.76341537 0.73893343 0.76066965 0.76026313        nan 0.75925484\n",
      "        nan        nan        nan 0.7629729  0.74766503 0.76204581\n",
      "        nan        nan 0.75340267 0.7620283  0.76693883 0.76143146\n",
      "        nan        nan 0.75693711        nan 0.75613192 0.75401258\n",
      "        nan 0.75686021 0.76263323 0.75965819 0.76065194        nan\n",
      " 0.72707834        nan        nan 0.76809495        nan 0.72707834\n",
      " 0.75624403 0.76126314        nan 0.75204872        nan        nan\n",
      "        nan        nan 0.76631878        nan        nan        nan\n",
      " 0.73557163 0.75766043        nan        nan        nan 0.75765525\n",
      " 0.76039273        nan 0.75050508        nan        nan 0.75333292\n",
      "        nan 0.75571719 0.76312234 0.73653207        nan        nan\n",
      " 0.74243972 0.76317117 0.75479971        nan 0.75604092 0.76162148\n",
      " 0.75152989        nan        nan 0.75762749 0.75290796        nan\n",
      "        nan        nan        nan 0.75543499        nan        nan\n",
      " 0.75503895 0.75844757        nan        nan 0.75581196        nan\n",
      " 0.74710592 0.7432961         nan        nan        nan 0.75943735\n",
      " 0.76102285 0.75518472 0.75494113 0.73827004        nan        nan\n",
      "        nan 0.75767784 0.68802646 0.76525989 0.75556448 0.75604092\n",
      "        nan        nan 0.75511313        nan 0.75321446        nan\n",
      "        nan 0.75222769        nan 0.75698767        nan 0.75601275\n",
      "        nan 0.76492005        nan 0.76285975        nan 0.74733872\n",
      " 0.75908282 0.70943161        nan        nan        nan        nan\n",
      "        nan        nan 0.75000384        nan        nan        nan\n",
      "        nan 0.75802504        nan        nan 0.75832603        nan\n",
      " 0.75193755        nan 0.75521062        nan 0.75989428        nan\n",
      "        nan 0.75743167        nan 0.76160074 0.75616638 0.7584819\n",
      "        nan        nan 0.75667208        nan        nan 0.75670787\n",
      "        nan 0.75536167        nan        nan        nan 0.76580405\n",
      " 0.76180085 0.73762676        nan        nan        nan        nan\n",
      " 0.75141124        nan 0.76298825        nan        nan        nan\n",
      " 0.76275914        nan 0.75735853 0.76174935        nan        nan\n",
      "        nan 0.75193755 0.75425301        nan 0.76367554 0.74586789\n",
      "        nan 0.76600482        nan 0.76175228        nan        nan\n",
      "        nan        nan        nan        nan 0.75885631        nan\n",
      "        nan        nan 0.7632037  0.76323932        nan        nan\n",
      " 0.75378405 0.76302579        nan        nan        nan 0.76093717\n",
      " 0.76292615        nan        nan        nan        nan 0.75674788]\n",
      "  warnings.warn(\n",
      "C:\\Users\\jobqu\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.6856900447798496, 'gamma': 0.00019706016482668386, 'learning_rate': 0.04274716034639669, 'max_depth': 5, 'n_estimators': 10, 'scale_pos_weight': 80}\n",
      "0.7680949532930706\n",
      "0.8079706026201492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[28492, 13938],\n",
       "       [  105,   427]], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(n_jobs = -1, objective = 'binary:logistic', eval_metric = 'auc', \n",
    "                            scale_pos_weight = 99) #, use_label_encoder=False)\n",
    "\n",
    "xgb_distributions = {'n_estimators': [4, 5, 6, 7, 10, 50, 100], \n",
    "                       'max_depth': [2, 3, 4, 5, 6, 7, 8],\n",
    "                       'gamma': loguniform(1e-4, 1e0),    \n",
    "                       'learning_rate': loguniform(1e-4, 1e0), \n",
    "                       'colsample_bytree':  stats.uniform(0.5, 1.0),\n",
    "                       'scale_pos_weight': [1, 80, 99, 100]}\n",
    "\n",
    "xgb_r_cv = RandomizedSearchCV(xgb_clf, \n",
    "                        param_distributions = xgb_distributions, \n",
    "                        n_iter = 300,\n",
    "                        scoring = 'roc_auc', \n",
    "                        n_jobs = -1, \n",
    "                        verbose = 3, \n",
    "                        cv = 3)\n",
    "\n",
    "xgb_r_cv.fit(X_filtered, y)\n",
    "\n",
    "print(xgb_r_cv.best_params_)\n",
    "print(xgb_r_cv.best_score_)\n",
    "\n",
    "\n",
    "xgb_final = xgb_r_cv.best_estimator_\n",
    "\n",
    "y_pred_prob = xgb_final.predict_proba(X_filtered)[:,1]\n",
    "\n",
    "print(roc_auc_score(y, y_pred_prob))\n",
    "\n",
    "confusion_matrix(y, xgb_final.predict(X_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-dominant",
   "metadata": {},
   "source": [
    "### Con Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "hidden-signal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 400 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jobqu\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.7612159         nan        nan        nan 0.74035046\n",
      " 0.67568133 0.72810689        nan        nan 0.75365393 0.74898323\n",
      "        nan        nan        nan        nan 0.74452261 0.76058528\n",
      "        nan        nan 0.76066503        nan 0.75183987        nan\n",
      " 0.76076566 0.73369853 0.72810689 0.75873099 0.75680322        nan\n",
      "        nan 0.75888689        nan        nan        nan        nan\n",
      "        nan 0.72463393 0.75552379        nan 0.76066325 0.7608379\n",
      "        nan        nan 0.7569124         nan        nan 0.74001326\n",
      "        nan 0.75905552 0.74003536 0.76392598        nan 0.76064252\n",
      "        nan 0.75614157        nan 0.75926229        nan        nan\n",
      "        nan        nan        nan 0.76237045 0.75579268        nan\n",
      " 0.76211058 0.76026813        nan 0.74628221 0.75843776 0.75834443\n",
      " 0.75879871 0.74226737 0.75915353 0.75708127 0.7572484  0.75516658\n",
      " 0.75832432 0.75525324        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.75818814        nan\n",
      "        nan 0.7518973         nan 0.75571798        nan        nan\n",
      "        nan 0.76884566 0.75880761        nan 0.73258205        nan\n",
      "        nan        nan 0.75899526 0.75711287        nan        nan\n",
      "        nan 0.76142134        nan        nan        nan        nan\n",
      "        nan 0.75440523        nan 0.75102949 0.72810689        nan\n",
      " 0.72722096 0.76137091        nan        nan        nan 0.72823636\n",
      "        nan 0.76092168 0.75439101        nan 0.74507247        nan\n",
      "        nan        nan        nan 0.75965184        nan        nan\n",
      "        nan        nan        nan 0.74068738        nan        nan\n",
      " 0.75390573 0.69237329 0.75548872        nan 0.75992463        nan\n",
      " 0.71620251 0.75859009 0.76046684        nan        nan 0.76134001\n",
      "        nan        nan 0.7506499  0.72810689        nan 0.75436517\n",
      "        nan 0.75810452        nan        nan 0.75845302 0.74923812\n",
      "        nan 0.75371043 0.72810689        nan 0.75440523        nan\n",
      "        nan        nan 0.76123477 0.76549291 0.76120704 0.76093314\n",
      "        nan 0.75355173        nan 0.75436045 0.7383567  0.71602023\n",
      " 0.76125878        nan        nan 0.71161242 0.75907461 0.72771842\n",
      "        nan        nan 0.76223982 0.75461367 0.69237329 0.75110403\n",
      "        nan        nan 0.72946618        nan        nan        nan\n",
      "        nan 0.76098206        nan        nan 0.76162401 0.7638758\n",
      " 0.75454982        nan 0.74801857 0.76139465 0.76240115        nan\n",
      " 0.75629976 0.75855365 0.75131865 0.7616491  0.74943656        nan\n",
      " 0.75535837        nan        nan 0.7575805  0.71359497        nan\n",
      " 0.76070111 0.75337695 0.72738145        nan 0.75612817 0.76215302\n",
      "        nan 0.7670214         nan 0.75688714        nan        nan\n",
      "        nan 0.75757587 0.75010954        nan 0.7556733         nan\n",
      "        nan        nan 0.75370567        nan        nan        nan\n",
      " 0.74131481 0.76066936        nan        nan 0.76077688 0.74872746\n",
      " 0.70513116 0.72815265 0.76114094        nan        nan 0.75831008\n",
      "        nan 0.76315248 0.73422183 0.72823636        nan 0.71112052\n",
      " 0.75838939 0.75430553        nan        nan 0.75629805        nan\n",
      " 0.76191273        nan 0.7541482         nan        nan        nan\n",
      " 0.74328887        nan 0.75258364 0.7526401  0.74001326        nan\n",
      "        nan        nan        nan 0.75799483        nan 0.75747368\n",
      "        nan 0.72901583 0.75649695        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.75027914 0.73810251\n",
      "        nan 0.75614157 0.7596282         nan 0.74459232 0.75756679\n",
      " 0.75150549        nan 0.75160815 0.75352784        nan 0.76163234\n",
      " 0.69666409 0.73637998        nan        nan 0.75646709        nan\n",
      "        nan        nan        nan        nan 0.75215507        nan\n",
      "        nan        nan 0.72810689        nan        nan        nan\n",
      " 0.75927405 0.75198227        nan 0.7089492         nan        nan\n",
      " 0.74061487 0.75680322        nan        nan        nan 0.75481504\n",
      "        nan        nan 0.74878375 0.7588392  0.74580267 0.75935527\n",
      " 0.74721234 0.75384352        nan        nan 0.75601156 0.75993098\n",
      "        nan 0.76159459        nan 0.73670839        nan        nan\n",
      " 0.75397025        nan 0.75895535 0.75676244 0.7395643         nan\n",
      "        nan 0.75965817        nan        nan        nan 0.7568402\n",
      " 0.76027649        nan        nan 0.75605383        nan        nan\n",
      "        nan 0.74442381        nan 0.75808768        nan        nan\n",
      " 0.74681018 0.74481228 0.76132169 0.72722096 0.75613996 0.75743923\n",
      "        nan 0.72826001        nan 0.75783061]\n",
      "  warnings.warn(\n",
      "C:\\Users\\jobqu\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.682998796281071, 'gamma': 0.012626100564399077, 'learning_rate': 0.03295115006484807, 'max_depth': 6, 'n_estimators': 100, 'scale_pos_weight': 1}\n",
      "0.768845663365538\n",
      "0.7979840616532079\n",
      "0.7877102827632051\n",
      "[[33943     0]\n",
      " [  426     0]]\n",
      "[[8487    0]\n",
      " [ 106    0]]\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(n_jobs = -1, objective = 'binary:logistic', eval_metric = 'auc') #, use_label_encoder=False)\n",
    "\n",
    "xgb_distributions = {'n_estimators': [4, 5, 6, 7, 10, 50, 100], \n",
    "                       'max_depth': [2, 3, 4, 5, 6, 7, 8],\n",
    "                       'gamma': loguniform(1e-4, 1e0),    \n",
    "                       'learning_rate': loguniform(1e-4, 1e0), \n",
    "                       'colsample_bytree':  stats.uniform(0.5, 1.0),\n",
    "                       'scale_pos_weight': [1, 80, 99, 100]}\n",
    "\n",
    "xgb_r_cv = RandomizedSearchCV(xgb_clf, \n",
    "                        param_distributions = xgb_distributions, \n",
    "                        n_iter = 400,\n",
    "                        scoring = 'roc_auc', \n",
    "                        n_jobs = -1, \n",
    "                        verbose = 3, \n",
    "                        cv = 3)\n",
    "\n",
    "xgb_r_cv.fit(Xf_train, yf_train)\n",
    "\n",
    "print(xgb_r_cv.best_params_)\n",
    "print(xgb_r_cv.best_score_)\n",
    "\n",
    "\n",
    "xgb_final = xgb_r_cv.best_estimator_\n",
    "\n",
    "y_prob_ftrain = xgb_final.predict_proba(Xf_train)[:,1]\n",
    "y_prob_ftest = xgb_final.predict_proba(Xf_test)[:,1]\n",
    "\n",
    "print(roc_auc_score(yf_train, y_prob_ftrain))\n",
    "print(roc_auc_score(yf_test, y_prob_ftest))\n",
    "\n",
    "print(confusion_matrix(yf_train, xgb_final.predict(Xf_train)))\n",
    "print(confusion_matrix(yf_test, xgb_final.predict(Xf_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-august",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "colonial-irish",
   "metadata": {},
   "source": [
    "### ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "sexual-angola",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "{'learning_rate': 0.1, 'n_estimators': 50}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7620436129927999"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adab_clf = AdaBoostClassifier()\n",
    "\n",
    "adab_hyperparams = {'n_estimators': [5, 10, 50, 100, 200], \n",
    "                    'learning_rate': [0.01, 0.1, 1, 2]}\n",
    "\n",
    "\n",
    "adab_cv = GridSearchCV(adab_clf, adab_hyperparams, scoring = 'roc_auc', n_jobs = -1, verbose = 3, cv = 3)\n",
    "\n",
    "adab_cv.fit(X, y)\n",
    "\n",
    "print(adab_cv.best_params_)\n",
    "adab_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "silver-identifier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7757741188937464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[42430,     0],\n",
       "       [  532,     0]], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adab_final = adab_cv.best_estimator_\n",
    "\n",
    "y_pred_prob = adab_final.predict_proba(X)[:,1]\n",
    "\n",
    "print(roc_auc_score(y, y_pred_prob))\n",
    "\n",
    "confusion_matrix(y, adab_final.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-specification",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "occupational-omega",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0001,\n",
       " 'average': False,\n",
       " 'class_weight': None,\n",
       " 'early_stopping': False,\n",
       " 'epsilon': 0.1,\n",
       " 'eta0': 0.0,\n",
       " 'fit_intercept': True,\n",
       " 'l1_ratio': 0.15,\n",
       " 'learning_rate': 'optimal',\n",
       " 'loss': 'hinge',\n",
       " 'max_iter': 1000,\n",
       " 'n_iter_no_change': 5,\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'power_t': 0.5,\n",
       " 'random_state': None,\n",
       " 'shuffle': True,\n",
       " 'tol': 0.001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier()\n",
    "\n",
    "sgd_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "micro-hours",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "{'alpha': 5e-05, 'penalty': 'l1'}\n",
      "0.6398333146377478\n",
      "0.6724003400558904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[30681, 11749],\n",
       "       [  201,   331]], dtype=int64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(class_weight = 'balanced', early_stopping = True, loss = 'modified_huber')\n",
    "\n",
    "sgd_hyperparams = {'penalty': ['l2', 'l1', 'elasticnet'], \n",
    "                   'alpha': [0.00005, 0.0001, 0.0002]}\n",
    "\n",
    "sgd_cv = GridSearchCV(sgd_clf, sgd_hyperparams, scoring = 'roc_auc', n_jobs = -1, verbose = 3, cv = 3)\n",
    "\n",
    "sgd_cv.fit(X, y)\n",
    "\n",
    "print(sgd_cv.best_params_)\n",
    "print(sgd_cv.best_score_)\n",
    "\n",
    "### \n",
    "\n",
    "sgd_final = sgd_cv.best_estimator_\n",
    "\n",
    "y_pred_prob = sgd_final.predict_proba(X)[:,1]\n",
    "\n",
    "print(roc_auc_score(y, y_pred_prob))\n",
    "\n",
    "confusion_matrix(y, sgd_final.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "improving-eating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "{'alpha': 0.0001, 'penalty': 'elasticnet'}\n",
      "0.6259256825330947\n",
      "0.6384598516087533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[22161, 20269],\n",
       "       [  141,   391]], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(class_weight = 'balanced', early_stopping = True, loss = 'modified_huber')\n",
    "\n",
    "sgd_hyperparams = {'penalty': ['l2', 'l1', 'elasticnet'], \n",
    "                   'alpha': [0.00005, 0.0001, 0.0002]}\n",
    "\n",
    "sgd_cv = GridSearchCV(sgd_clf, sgd_hyperparams, scoring = 'roc_auc', n_jobs = -1, verbose = 3, cv = 3)\n",
    "\n",
    "sgd_cv.fit(X_filtered, y)\n",
    "\n",
    "print(sgd_cv.best_params_)\n",
    "print(sgd_cv.best_score_)\n",
    "\n",
    "### \n",
    "\n",
    "sgd_final = sgd_cv.best_estimator_\n",
    "\n",
    "y_pred_prob = sgd_final.predict_proba(X_filtered)[:,1]\n",
    "\n",
    "print(roc_auc_score(y, y_pred_prob))\n",
    "\n",
    "confusion_matrix(y, sgd_final.predict(X_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-shopper",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-belarus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-baltimore",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipelines = {'l1': make_pipeline(StandardScaler(),\n",
    "                                LogisticRegression(random_state = 123, penalty='l1')),\n",
    "            'l2': make_pipeline(StandardScaler(),\n",
    "                               LogisticRegression(random_state = 123, penalty='l2')),\n",
    "            'rf': make_pipeline(StandardScaler(),\n",
    "                                RandomForestClassifier(random_state = 123)),\n",
    "            'gb': make_pipeline(StandardScaler(),\n",
    "                                GradientBoostingClassifier(random_state=123))\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-ownership",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-currency",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-first",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-appointment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-skirt",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-lewis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "modular-fruit",
   "metadata": {},
   "source": [
    "## Part 3: Kaggle Competition\n",
    "\n",
    "Now that you've created a model to predict which individuals are most likely to respond to a mailout campaign, it's time to test that model in competition through Kaggle. If you click on the link [here](http://www.kaggle.com/t/21e6d45d4c574c7fa2d868f0e8c83140), you'll be taken to the competition page where, if you have a Kaggle account, you can enter. If you're one of the top performers, you may have the chance to be contacted by a hiring manager from Arvato or Bertelsmann for an interview!\n",
    "\n",
    "Your entry to the competition should be a CSV file with two columns. The first column should be a copy of \"LNR\", which acts as an ID number for each individual in the \"TEST\" partition. The second column, \"RESPONSE\", should be some measure of how likely each individual became a customer – this might not be a straightforward probability. As you should have found in Part 2, there is a large output class imbalance, where most individuals did not respond to the mailout. Thus, predicting individual classes and using accuracy does not seem to be an appropriate performance evaluation method. Instead, the competition will be using AUC to evaluate performance. The exact values of the \"RESPONSE\" column do not matter as much: only that the higher values try to capture as many of the actual customers as possible, early in the ROC curve sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "indian-crazy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jobqu\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3155: DtypeWarning: Columns (19,20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial amount of missing values: 2186771\n",
      "\n",
      "Reading the description of attributes table....\n",
      "\n",
      "Missing values after including missing codes 2322980\n",
      "Additional missing values: 136209\n",
      "\n",
      "Starting the cleaning of attributes and feature engineering...\n",
      "\n",
      "\n",
      "Missing values: 0\n",
      "(42833, 213)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARBEIT</th>\n",
       "      <th>BALLRAUM</th>\n",
       "      <th>CJT_KATALOGNUTZER</th>\n",
       "      <th>CJT_TYP_1</th>\n",
       "      <th>CJT_TYP_2</th>\n",
       "      <th>CJT_TYP_3</th>\n",
       "      <th>CJT_TYP_4</th>\n",
       "      <th>CJT_TYP_5</th>\n",
       "      <th>CJT_TYP_6</th>\n",
       "      <th>D19_BANKEN_ANZ_12</th>\n",
       "      <th>...</th>\n",
       "      <th>REGIOTYP_7.0</th>\n",
       "      <th>CAMEO_DEUG_2015_1.0</th>\n",
       "      <th>CAMEO_DEUG_2015_2.0</th>\n",
       "      <th>CAMEO_DEUG_2015_3.0</th>\n",
       "      <th>CAMEO_DEUG_2015_4.0</th>\n",
       "      <th>CAMEO_DEUG_2015_5.0</th>\n",
       "      <th>CAMEO_DEUG_2015_6.0</th>\n",
       "      <th>CAMEO_DEUG_2015_7.0</th>\n",
       "      <th>CAMEO_DEUG_2015_8.0</th>\n",
       "      <th>CAMEO_DEUG_2015_9.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LNR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ARBEIT  BALLRAUM  CJT_KATALOGNUTZER  CJT_TYP_1  CJT_TYP_2  CJT_TYP_3  \\\n",
       "LNR                                                                          \n",
       "1754     3.0       6.0                5.0        1.0        2.0        5.0   \n",
       "1770     4.0       7.0                5.0        2.0        2.0        5.0   \n",
       "1465     4.0       1.0                5.0        2.0        2.0        5.0   \n",
       "1470     4.0       1.0                5.0        2.0        1.0        5.0   \n",
       "1478     3.0       6.0                1.0        3.0        2.0        4.0   \n",
       "\n",
       "      CJT_TYP_4  CJT_TYP_5  CJT_TYP_6  D19_BANKEN_ANZ_12  ...  REGIOTYP_7.0  \\\n",
       "LNR                                                       ...                 \n",
       "1754        5.0        5.0        5.0                  0  ...             0   \n",
       "1770        5.0        4.0        5.0                  0  ...             0   \n",
       "1465        5.0        5.0        5.0                  0  ...             0   \n",
       "1470        5.0        5.0        5.0                  0  ...             0   \n",
       "1478        4.0        4.0        3.0                  3  ...             0   \n",
       "\n",
       "      CAMEO_DEUG_2015_1.0  CAMEO_DEUG_2015_2.0  CAMEO_DEUG_2015_3.0  \\\n",
       "LNR                                                                   \n",
       "1754                    0                    1                    0   \n",
       "1770                    0                    0                    0   \n",
       "1465                    0                    0                    0   \n",
       "1470                    0                    1                    0   \n",
       "1478                    0                    0                    0   \n",
       "\n",
       "      CAMEO_DEUG_2015_4.0  CAMEO_DEUG_2015_5.0  CAMEO_DEUG_2015_6.0  \\\n",
       "LNR                                                                   \n",
       "1754                    0                    0                    0   \n",
       "1770                    0                    1                    0   \n",
       "1465                    0                    0                    0   \n",
       "1470                    0                    0                    0   \n",
       "1478                    0                    1                    0   \n",
       "\n",
       "      CAMEO_DEUG_2015_7.0  CAMEO_DEUG_2015_8.0  CAMEO_DEUG_2015_9.0  \n",
       "LNR                                                                  \n",
       "1754                    0                    0                    0  \n",
       "1770                    0                    0                    0  \n",
       "1465                    1                    0                    0  \n",
       "1470                    0                    0                    0  \n",
       "1478                    0                    0                    0  \n",
       "\n",
       "[5 rows x 212 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailout_test = pd.read_csv('data/Udacity_MAILOUT_052018_TEST.csv')\n",
    "\n",
    "test_clean = cleaning_functions.clean_data(mailout_test)\n",
    "\n",
    "print('\\n\\nMissing values:', test_clean.isnull().sum().sum()) \n",
    "\n",
    "print(test_clean.shape)\n",
    "\n",
    "test_clean.set_index(['LNR'], inplace = True)\n",
    "\n",
    "test_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "removable-amino",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler\n",
    "test_scaled = scaler.transform(test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "still-boston",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xgb_final.predict(test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "white-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xgb_final.predict_proba(test_scaled)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "accessory-ratio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42833, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LNR</th>\n",
       "      <th>RESPONSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1754</td>\n",
       "      <td>0.534138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1770</td>\n",
       "      <td>0.539665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1465</td>\n",
       "      <td>0.468753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1470</td>\n",
       "      <td>0.461999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1478</td>\n",
       "      <td>0.464511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LNR  RESPONSE\n",
       "0  1754  0.534138\n",
       "1  1770  0.539665\n",
       "2  1465  0.468753\n",
       "3  1470  0.461999\n",
       "4  1478  0.464511"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(preds, index = test_clean.index)\n",
    "\n",
    "pred_df.reset_index(inplace = True)\n",
    "\n",
    "pred_df.columns = ['LNR', 'RESPONSE']\n",
    "\n",
    "print(pred_df.shape)\n",
    "\n",
    "pred_df.head()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "trained-education",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "abandoned-playing",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('predictions_1.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-papua",
   "metadata": {},
   "source": [
    "### RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "documentary-complement",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jobqu\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3155: DtypeWarning: Columns (19,20) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial amount of missing values: 2186771\n",
      "\n",
      "Reading the description of attributes table....\n",
      "\n",
      "Missing values after including missing codes 2322980\n",
      "Additional missing values: 136209\n",
      "\n",
      "Starting the cleaning of attributes and feature engineering...\n",
      "\n",
      "\n",
      "Missing values: 0\n",
      "(42833, 213)\n",
      "(42833, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LNR</th>\n",
       "      <th>RESPONSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1754</td>\n",
       "      <td>0.026685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1770</td>\n",
       "      <td>0.037975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1465</td>\n",
       "      <td>0.002877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1470</td>\n",
       "      <td>0.002934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1478</td>\n",
       "      <td>0.011136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LNR  RESPONSE\n",
       "0  1754  0.026685\n",
       "1  1770  0.037975\n",
       "2  1465  0.002877\n",
       "3  1470  0.002934\n",
       "4  1478  0.011136"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailout_test = pd.read_csv('data/Udacity_MAILOUT_052018_TEST.csv')\n",
    "\n",
    "test_clean = cleaning_functions.clean_data(mailout_test)\n",
    "\n",
    "print('\\n\\nMissing values:', test_clean.isnull().sum().sum()) \n",
    "\n",
    "print(test_clean.shape)\n",
    "\n",
    "test_clean.set_index(['LNR'], inplace = True)\n",
    "\n",
    "# Scaler\n",
    "test_scaled = scaler.transform(test_clean)\n",
    "\n",
    "preds_2 = rfc_final.predict_proba(test_scaled)[:,1]\n",
    "\n",
    "\n",
    "preds_2_df = pd.DataFrame(preds_2, index = test_clean.index)\n",
    "\n",
    "preds_2_df.reset_index(inplace = True)\n",
    "\n",
    "preds_2_df.columns = ['LNR', 'RESPONSE']\n",
    "\n",
    "print(preds_2_df.shape)\n",
    "\n",
    "preds_2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "broke-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_2_df.to_csv('predictions_2.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "controlling-poland",
   "metadata": {},
   "source": [
    "![img](Submit_2.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
